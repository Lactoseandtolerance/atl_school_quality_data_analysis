{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1682e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "print(\"Starting enhanced CSV parser for school data...\")\n",
    "\n",
    "# Function to detect CSV delimiter\n",
    "def detect_delimiter(file_path, num_lines=20):\n",
    "    \"\"\"Try to automatically detect the delimiter in a CSV file\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        # Read a small sample of the file\n",
    "        sample = ''.join(file.readline() for _ in range(num_lines))\n",
    "        \n",
    "        # Count potential delimiters\n",
    "        delimiters = [',', ';', '\\t', '|']\n",
    "        delimiter_counts = {}\n",
    "        \n",
    "        for delimiter in delimiters:\n",
    "            delimiter_counts[delimiter] = sample.count(delimiter)\n",
    "        \n",
    "        # Return the delimiter with the highest count\n",
    "        most_common_delimiter = max(delimiter_counts, key=delimiter_counts.get)\n",
    "        print(f\"Detected delimiter: '{most_common_delimiter}' (found {delimiter_counts[most_common_delimiter]} times in sample)\")\n",
    "        \n",
    "        return most_common_delimiter\n",
    "\n",
    "# Function to try multiple approaches to read the CSV\n",
    "def read_csv_robust(file_path):\n",
    "    \"\"\"Try multiple approaches to read a problematic CSV file\"\"\"\n",
    "    # First, try to detect the delimiter\n",
    "    try:\n",
    "        delimiter = detect_delimiter(file_path)\n",
    "        df = pd.read_csv(file_path, delimiter=delimiter, error_bad_lines=False, warn_bad_lines=True)\n",
    "        print(f\"Successfully read CSV with delimiter: '{delimiter}'\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"First attempt failed: {e}\")\n",
    "    \n",
    "    # Second, try with Python's csv module for more flexibility\n",
    "    try:\n",
    "        print(\"Trying with csv module...\")\n",
    "        rows = []\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "            # Try to sniff the dialect/format\n",
    "            sample = file.read(4096)\n",
    "            file.seek(0)\n",
    "            \n",
    "            try:\n",
    "                dialect = csv.Sniffer().sniff(sample)\n",
    "                print(f\"Detected dialect with delimiter: '{dialect.delimiter}'\")\n",
    "                reader = csv.reader(file, dialect)\n",
    "            except:\n",
    "                print(\"Could not detect dialect, using excel format\")\n",
    "                reader = csv.reader(file)\n",
    "            \n",
    "            headers = next(reader)\n",
    "            for row in reader:\n",
    "                # Skip empty rows or rows with different column counts\n",
    "                if row and len(row) == len(headers):\n",
    "                    rows.append(row)\n",
    "        \n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        print(f\"Successfully read {len(df)} rows using csv module\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Second attempt failed: {e}\")\n",
    "    \n",
    "    # Third, try reading with different encodings and error handling\n",
    "    for encoding in ['utf-8', 'latin1', 'iso-8859-1']:\n",
    "        try:\n",
    "            print(f\"Trying with encoding: {encoding}\")\n",
    "            df = pd.read_csv(file_path, encoding=encoding, engine='python')\n",
    "            print(f\"Successfully read CSV with encoding: {encoding}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt with {encoding} failed: {e}\")\n",
    "    \n",
    "    raise Exception(\"Could not read the CSV file after multiple attempts\")\n",
    "\n",
    "# Load the zipcodes data first (assuming it's simpler)\n",
    "try:\n",
    "    zipcodes_df = pd.read_csv('data/zipcodes.csv')\n",
    "    print(f\"Loaded {len(zipcodes_df)} target zip codes\")\n",
    "    \n",
    "    # Get the list of target zip codes\n",
    "    # Check for 'Zipcode' column in zipcodes_df\n",
    "    if 'Zipcode' in zipcodes_df.columns:\n",
    "        target_zips = zipcodes_df['Zipcode'].astype(str).tolist()\n",
    "    elif 'ZIP' in zipcodes_df.columns:\n",
    "        target_zips = zipcodes_df['ZIP'].astype(str).tolist()\n",
    "    elif 'zip' in zipcodes_df.columns:\n",
    "        target_zips = zipcodes_df['zip'].astype(str).tolist()\n",
    "    else:\n",
    "        # Take the first column as zip code\n",
    "        zip_col_name = zipcodes_df.columns[0]\n",
    "        target_zips = zipcodes_df[zip_col_name].astype(str).tolist()\n",
    "    \n",
    "    print(f\"Found {len(target_zips)} target zip codes\")\n",
    "    print(f\"Sample of target zip codes: {target_zips[:5]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading zipcodes.csv: {e}\")\n",
    "    print(\"Using default test zipcode list\")\n",
    "    target_zips = ['30306', '30307', '30308', '30309', '30310']  # Default test values\n",
    "\n",
    "# Try to load the NCES data with our robust method\n",
    "try:\n",
    "    print(\"\\nAttempting to read ELSI_NCES_GA_school_data.csv...\")\n",
    "    nces_data = read_csv_robust('data/raw/ELSI_NCES_GA_school_data.csv')\n",
    "    print(f\"Successfully loaded NCES data with {len(nces_data)} rows and {len(nces_data.columns)} columns\")\n",
    "    \n",
    "    # Display the first few columns to help identify the zip code column\n",
    "    print(\"\\nFirst 5 columns:\")\n",
    "    for i, col in enumerate(nces_data.columns[:5]):\n",
    "        print(f\"{i}: {col}\")\n",
    "    \n",
    "    # Display a small sample of rows to help understand the data\n",
    "    print(\"\\nSample of first 3 rows and 5 columns:\")\n",
    "    sample_df = nces_data.iloc[:3, :5]\n",
    "    print(sample_df)\n",
    "    \n",
    "    # Look for likely zip code columns\n",
    "    print(\"\\nLooking for zip code columns...\")\n",
    "    zip_col = None\n",
    "    possible_zip_cols = ['ZIP', 'Zip', 'zip', 'ZIP_CODE', 'Zip_Code', 'zip_code', \n",
    "                         'Postal', 'postal', 'Postal_Code', 'postal_code', \n",
    "                         'Location_ZIP', 'SCHZIP', 'SCH_ZIP', 'ZIP Code']\n",
    "    \n",
    "    for col in possible_zip_cols:\n",
    "        if col in nces_data.columns:\n",
    "            zip_col = col\n",
    "            print(f\"Found zip code column: {zip_col}\")\n",
    "            break\n",
    "    \n",
    "    # If no standard zip column found, try to identify it\n",
    "    if not zip_col:\n",
    "        # Look for column names containing 'zip'\n",
    "        for col in nces_data.columns:\n",
    "            if 'zip' in col.lower():\n",
    "                zip_col = col\n",
    "                print(f\"Found likely zip code column: {zip_col}\")\n",
    "                break\n",
    "        \n",
    "        # If still not found, examine a sample of each column to find zip code patterns\n",
    "        if not zip_col:\n",
    "            print(\"No standard zip code column found. Examining data patterns...\")\n",
    "            for col in nces_data.columns:\n",
    "                # Skip very large text fields \n",
    "                if nces_data[col].astype(str).str.len().max() > 20:\n",
    "                    continue\n",
    "                    \n",
    "                sample = nces_data[col].dropna().astype(str).iloc[:10].tolist()\n",
    "                # Check if values match 5-digit zip code pattern\n",
    "                zip_pattern_count = sum(1 for val in sample if len(str(val)) == 5 and str(val).isdigit())\n",
    "                if zip_pattern_count >= 3:  # If at least 3 values look like zip codes\n",
    "                    zip_col = col\n",
    "                    print(f\"Found likely zip code column based on data pattern: {zip_col}\")\n",
    "                    print(f\"Sample values: {sample[:5]}\")\n",
    "                    break\n",
    "    \n",
    "    # If still can't find zip column, list all columns and ask user to specify\n",
    "    if not zip_col:\n",
    "        print(\"\\nCouldn't automatically detect zip code column. Here are all columns:\")\n",
    "        for i, col in enumerate(nces_data.columns):\n",
    "            print(f\"{i}: {col}\")\n",
    "        \n",
    "        col_index = int(input(\"\\nEnter the column index for zip codes: \"))\n",
    "        zip_col = nces_data.columns[col_index]\n",
    "        print(f\"Using column '{zip_col}' for zip codes\")\n",
    "    \n",
    "    # Ensure zip codes are treated as strings\n",
    "    nces_data[zip_col] = nces_data[zip_col].astype(str)\n",
    "    \n",
    "    # Clean up zip codes (remove any spaces, trim to first 5 digits)\n",
    "    nces_data[zip_col] = nces_data[zip_col].str.replace(' ', '')\n",
    "    nces_data[zip_col] = nces_data[zip_col].str.extract(r'(\\d{5})').fillna(nces_data[zip_col])\n",
    "    \n",
    "    # Filter schools by target zip codes\n",
    "    filtered_schools = nces_data[nces_data[zip_col].isin(target_zips)]\n",
    "    print(f\"\\nFound {len(filtered_schools)} schools in the target zip codes\")\n",
    "    \n",
    "    # Check if any target zip codes have no schools\n",
    "    zips_with_schools = filtered_schools[zip_col].unique()\n",
    "    missing_zips = [z for z in target_zips if z not in zips_with_schools]\n",
    "    \n",
    "    if missing_zips:\n",
    "        print(f\"\\nWarning: {len(missing_zips)} target zip codes have no schools in the NCES data:\")\n",
    "        print(missing_zips)\n",
    "    \n",
    "    # Save the filtered data\n",
    "    filtered_schools.to_csv('data/aggregated/filtered_nces_schools.csv', index=False)\n",
    "    print(\"\\nFiltered schools data saved to 'filtered_nces_schools.csv'\")\n",
    "    \n",
    "    # Print schools per zip code\n",
    "    schools_per_zip = filtered_schools.groupby(zip_col).size()\n",
    "    print(\"\\nNumber of schools per zip code:\")\n",
    "    print(schools_per_zip)\n",
    "    \n",
    "    print(\"\\nSuccess! Processing complete.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error processing NCES data: {e}\")\n",
    "    print(\"\\nRecommendations for manual inspection:\")\n",
    "    print(\"1. Open ELSI_NCES_GA_school_data.csv in a text editor to check its format\")\n",
    "    print(\"2. Look for unusual characters or formatting issues\")\n",
    "    print(\"3. Try opening the file in Excel or another spreadsheet program and save it as a clean CSV\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
